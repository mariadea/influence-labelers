{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "pi_1 = 4.0\n",
    "pi_2= 0.8\n",
    "tau = 1.0\n",
    "rho= 0.02\n",
    "K=10\n",
    "params = {'layers': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../../data/ChildWelfare/X_preprocess.pkl', 'rb') as handle:\n",
    "    X,screener_ids,refer_ids,Y_observed,Y_human,Y_serv,Y_sub,colnames = pkl.load(handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data(X,  refer_ids, screener_ids, Y_human, Y_observed):\n",
    "    refer_ids_train, refer_ids_test = sklearn.model_selection.train_test_split(np.unique(refer_ids),test_size = 0.25)\n",
    "\n",
    "    X_train = X[[(r in refer_ids_train) for r in refer_ids],:]\n",
    "    X_test = X[[(r in refer_ids_test) for r in refer_ids],:]\n",
    "\n",
    "    Y_h_train = np.array(Y_human[[(r in refer_ids_train) for r in refer_ids]])\n",
    "    Y_h_test = np.array(Y_human[[(r in refer_ids_test) for r in refer_ids]])\n",
    "\n",
    "    Y_obs_train = np.array(Y_observed[[(r in refer_ids_train) for r in refer_ids]])\n",
    "    Y_obs_test = np.array(Y_observed[[(r in refer_ids_test) for r in refer_ids]])\n",
    "\n",
    "    screener_ids_train = np.array(np.array(screener_ids)[[(r in refer_ids_train) for r in refer_ids]])\n",
    "    screener_ids_test = np.array(np.array(screener_ids)[[(r in refer_ids_train) for r in refer_ids]])\n",
    "\n",
    "    Y_h_train = np.transpose(Y_h_train)[0]\n",
    "    Y_h_test = np.transpose(Y_h_test)[0]\n",
    "    Y_obs_train = np.transpose(Y_obs_train)[0]\n",
    "    Y_obs_test = np.transpose(Y_obs_test)[0]\n",
    "    \n",
    "    return(refer_ids_train, refer_ids_test,X_train,X_test,Y_h_train,Y_h_test,Y_obs_train,Y_obs_test,screener_ids_train,screener_ids_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "refer_ids_train, refer_ids_test,X_train,X_test,Y_h_train,Y_h_test,Y_obs_train,Y_obs_test, screener_ids_train,screener_ids_test = partition_data(X,  refer_ids, screener_ids, Y_human, Y_observed)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.598: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in [0.001, 0.01]:\n",
    "    try:\n",
    "        model = BinaryMLP(**params)\n",
    "        model = model.fit(X_train, tar_train['D'], screener_ids_train, l1_penalty = l1_penalty)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e, l1_penalty)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amalgamate_and_hybrid(X,  refer_ids, screener_ids, Y_human, Y_observed, fit_classifier ='logit', f_y_hyb = 'retrain'):\n",
    "    #partition data\n",
    "    \n",
    "    if fit_classifier =='logit':\n",
    "        clf_obs = linear_model.LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "        clf_amalg = linear_model.LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "        clf_human = linear_model.LogisticRegression(penalty = 'l2', solver = 'liblinear')\n",
    "    if fit_classifier =='rf':\n",
    "        param_grid = {'min_samples_leaf':[10, 25, 50]}\n",
    "        clf_obs = RandomForestClassifier(random_state=0)\n",
    "        clf_amalg = RandomForestClassifier(random_state=0)\n",
    "        clf_human = RandomForestClassifier(random_state=0)\n",
    "        \n",
    "    #calculate consistency through cv . in train fols\n",
    "    M_inf, Y_pred_h, Agr1, Agr2 = label_agreeability(X_train,Y_h_train,screener_ids_train,0.05)\n",
    "    high_agr = np.where((Agr2[0]> pi_2) & (Agr1[0]> pi_1))\n",
    "    \n",
    "    #amalgamate labels\n",
    "    Y_amalg_train = np.copy(Y_obs_train)\n",
    "    high_agr_correct = [idx for idx in high_agr[0] if np.abs(Y_pred_h[0][idx]-Y_h_train[idx]) < 0.05 ]\n",
    "    Y_amalg_train[high_agr_correct] = (1-tau)*Y_obs_train[high_agr_correct]+tau*Y_h_train[high_agr_correct]\n",
    "    \n",
    "    #train model on observed labels (on portion that is screened-in)\n",
    "    if fit_classifier =='logit':\n",
    "        clf_obs.fit(X_train[Y_h_train==1,:], Y_obs_train[Y_h_train==1])\n",
    "    if fit_classifier =='rf':\n",
    "        grid_search = GridSearchCV(estimator = clf_obs, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 10, verbose = 1)\n",
    "        grid_search.fit(X_train[Y_h_train==1,:], Y_obs_train[Y_h_train==1])\n",
    "        clf_obs = grid_search.best_estimator_\n",
    "    \n",
    "    Y_pred_obs_train = clf_obs.predict_proba(X_train[Y_h_train==1,:])[:, 1]\n",
    "    Y_pred_obs_test = clf_obs.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_obs_train[Y_h_train==1], Y_pred_obs_train)\n",
    "    print(\"AUC_train f_y\", metrics.auc(fpr, tpr))\n",
    "    \n",
    "    #train model on amalgamated labels\n",
    "    idx_amalg_train = np.unique(np.concatenate((np.where(Y_h_train==1)[0], np.array(high_agr_correct))))\n",
    "    idx_amalg_train = idx_amalg_train.astype(int)\n",
    "    if fit_classifier =='logit':\n",
    "        clf_amalg.fit(X_train[idx_amalg_train,:], Y_amalg_train[idx_amalg_train])\n",
    "    if fit_classifier =='rf':\n",
    "        grid_search = GridSearchCV(estimator = clf_amalg, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 10, verbose = 1)\n",
    "        grid_search.fit(X_train[idx_amalg_train,:], Y_amalg_train[idx_amalg_train])\n",
    "        clf_amalg = grid_search.best_estimator_\n",
    "    \n",
    "    Y_pred_amalg_train = clf_amalg.predict_proba(X_train[idx_amalg_train,:])[:, 1]\n",
    "    Y_pred_amalg_test= clf_amalg.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_amalg_train[idx_amalg_train], Y_pred_amalg_train)\n",
    "    print(\"AUC_train f_A\", metrics.auc(fpr, tpr))\n",
    "    \n",
    "    #train model on human decisions\n",
    "    if fit_classifier =='logit':\n",
    "        clf_human.fit(X_train, Y_h_train)\n",
    "    if fit_classifier =='rf':\n",
    "        grid_search = GridSearchCV(estimator = clf_human, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = 10, verbose = 1)\n",
    "        grid_search.fit(X_train, Y_h_train)\n",
    "        clf_human = grid_search.best_estimator_\n",
    "    \n",
    "    Y_pred_h_train = clf_human.predict_proba(X_train)[:, 1]\n",
    "    Y_pred_h_test = clf_human.predict_proba(X_test)[:, 1]\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(Y_h_train, Y_pred_h_train)\n",
    "    print(\"AUC_train f_h\", metrics.auc(fpr, tpr))\n",
    "    \n",
    "    #Determine which test instances are in set A\n",
    "    M_inf_test, Y_pred_h_test_L1, Agr1_test, Agr2_test = label_agreeability_test(X_train, X_test, Y_h_train, screener_ids_train, rho)\n",
    "    #idx of high_agreement instances\n",
    "    high_agr_test = np.where((Agr2_test[0]> pi_2) & (Agr1_test[0]> pi_1))[0]\n",
    "    \n",
    "    \n",
    "    #hybrid predictions: if x in A->f_h, if x not in A->f_y\n",
    "    Y_pred_hybrid_test = np.copy(Y_pred_obs_test)\n",
    "    \n",
    "    \n",
    "    #Assign predictions of human model to high-consistency set for hybrid approach \n",
    "    #uses same model as the one used to obtain set A_test\n",
    "    if f_y_hyb=='retrain':\n",
    "        Y_pred_hybrid_test[high_agr_test] = Y_pred_h_test[high_agr_test]\n",
    "    else:\n",
    "        Y_pred_hybrid_test[high_agr_test] = Y_pred_h_test_L1[high_agr_test]\n",
    "    #uses separate human model (L2) to ensure comparability with amalgamated model\n",
    "    \n",
    "    \n",
    "    \n",
    "    return(Y_pred_hybrid_test, Y_pred_obs_test, Y_pred_amalg_test, Y_pred_h_test, refer_ids_train, refer_ids_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

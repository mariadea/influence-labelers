{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library for studying the different models\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook explores how to choose the parameters of interest on the MIMIC example, and explore how to measure potential bias reinforcement. It shows step by step how to:\n",
    "1. Build the proposed amalgamation approach\n",
    "2. Compute performance\n",
    "3. Measure the influence (per group)\n",
    "4. Measure the different metrics (per group)\n",
    "5. Measure the percentage of amalgamation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = \"../data/triage_scenario_4bis.csv\" # Opne data of interest 4bis corresponds to the biased scenario.\n",
    "selective_labels = False # Is it a case of selective labels (only observe the outcome for patients filtered by nurse: D == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the data\n",
    "triage = pd.read_csv(data_set, index_col = [0, 1])\n",
    "covariates, target, nurses = triage.drop(columns = ['D', 'Y1', 'Y2', 'YC', 'nurse']), triage[['D', 'Y1', 'Y2', 'YC']], triage['nurse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in a 80% train, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_train, cov_test, tar_train, tar_test, nur_train, nur_test = train_test_split(covariates, target, nurses, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's characteristics\n",
    "params = {'layers': [[50]]} # If = [[]] equivalent to a simple logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(predictions, p = 0.3):\n",
    "    # Overall Performances\n",
    "    print('Performance')\n",
    "    for tar in ['Y1', 'Y2', 'YC', 'D']:\n",
    "        print('{} - AUC: {:.3f}'.format(tar, roc_auc_score(tar_test[tar], predictions)))\n",
    "\n",
    "        try:\n",
    "            predictions = pd.Series(predictions, index = tar_test.index)\n",
    "            bot = predictions.nsmallest(n = int(p * len(predictions)), keep = 'all').index\n",
    "            female = covariates.loc[predictions.index].Group == 1\n",
    "            bot_female = bot.intersection(female[female].index)\n",
    "            bot_male = bot.intersection(female[~female].index)\n",
    "\n",
    "            print('{} - Female TNR: {:.3f}'.format(tar, 1 - tar_test[tar].loc[bot_female].mean()))\n",
    "            print('{} - Female PNR: {:.3f}'.format(tar, len(bot_female) / female.sum()))\n",
    "            print()\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train on decision\n",
    "\n",
    "Similarly to `Triage - MIMIC.ipynb`, we first train a model and estimate the influence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_D = BinaryMLP(**params)\n",
    "f_D = f_D.fit(cov_train, tar_train['D'], nur_train, platt_calibration = True)\n",
    "predictions_d = f_D.predict(cov_test)\n",
    "evaluate(predictions_d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first model mimics the human decision. We measure the true negative rate and predicted rate in the protected group. A discrepancy between $f_h$ and $f_Y$ could indicate expert bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Agreement computation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold evaluation of influences\n",
    "folds, predictions, influence = influence_cv(BinaryMLP, cov_train, tar_train['D'], nur_train, params = params, l1_penalties = [0.001, 0.01, 0.1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step compute the influence of the training point in a cross validation fashion. One can then look at:\n",
    "- Distribution of predictions\n",
    "- Distribution of influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_series = pd.Series(predictions, index = cov_train.index, name = '$f_H$')\n",
    "sns.histplot(x ='$f_H$', hue = 'Group', data = pd.concat([cov_train.Group.replace({0: 'Male', 1: 'Female'}), pred_series], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unexplained group differences is sign that experts might be biased against one group. Nonetheless, user should take into account domain specific expertise as distributions might differ (e.g. breast cancer might impact male differently and the physician decision might reflect this difference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean influence per group\n",
    "inf_series = pd.DataFrame(influence.T, index = cov_train.index)\n",
    "pd.concat([cov_train.Group.replace({0: 'Male', 1: 'Female'}), inf_series], 1).groupby('Group').mean().T.plot.scatter('Female', 'Male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers in this plot represent expert who have a strong impact in a different direction than all other experts. \n",
    "\n",
    "One can then compute the different metrics that aim to measure consensus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics agreeability\n",
    "center_metric, opposing_metric = compute_agreeability(influence, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze confident points\n",
    "delta = 0.05 # Control which point to consider from a confience point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select points with high confidence\n",
    "high_conf = (predictions > (1 - delta)) | (predictions < delta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the selected points, one can study the different metrics quantifying the consensus beteween expert obtained for each points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1_series = pd.Series(center_metric, index = cov_train.index, name = '$m_1$')\n",
    "sns.histplot(x ='$m_1$', hue = 'Group', data = pd.concat([cov_train.Group.replace({0: 'Male', 1: 'Female'}), m1_series], 1)[high_conf], stat = \"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first metric measures the **center of mass**: *higher the value, more experts agree*. In this scenario, note how the female distribution is shifted due to the bias of one expert. This shift indicates that less experts agree on this particular group. \n",
    "\n",
    "In this context choosing $\\gamma_1$ at 6 or 7 allows to capture a large amount of the agreement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2_series = pd.Series(opposing_metric, index = cov_train.index, name = '$m_2$')\n",
    "sns.histplot(x ='$m_2$', hue = 'Group', data = pd.concat([cov_train.Group.replace({0: 'Male', 1: 'Female'}), m2_series], 1)[high_conf], stat = \"density\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This second metric measures how **aligned is the influence**: *larger it is, more expert are going in the same direction*.\n",
    "\n",
    "Here, the shift in the female distribution shows that a small set of expert is driving the decision for this group. To be conservative, one would want to correct for this non consensus, i.e. any threshold $\\gamma_2 > 0.4$ would ignore these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amalgation parameters choice\n",
    "pi_1 = 6 # Control criterion on centre mass metric\n",
    "pi_2 = 0.8 # Control criterion on opposing metric\n",
    "pi_3 = 0.002 # On flatness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following this choice, one can amalgamte the human decision and the observed outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria on amalgamation\n",
    "flat_influence = (np.abs(influence) > pi_3).sum(0) == 0\n",
    "high_agr = (((center_metric > pi_1) & (opposing_metric > pi_2)) | flat_influence) & high_conf\n",
    "high_agr_correct = ((predictions - tar_train['D']).abs() < delta) & high_agr\n",
    "print(\"This choice of parameters leads to an amalgamation of : {:.2f} % of the data\".format(100 * np.mean(high_agr_correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amalgamated labels\n",
    "tar_train['Ya'] = tar_train['Y1']# Initialize as human decision\n",
    "tar_train.loc[high_agr_correct, 'Ya'] = tar_train['D'][high_agr_correct] # Change the point to amalgamate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_amalg = ((tar_train['D'] == 1) | high_agr_correct) if selective_labels else tar_train['D'].isin([0, 1]) # Retrain the model on the set of observed points\n",
    "print(\"Use: {:.2f} % of data\".format(100 * index_amalg.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_A = BinaryMLP(**params)\n",
    "f_A = f_A.fit(cov_train[index_amalg], tar_train[index_amalg]['Ya'], nur_train[index_amalg])\n",
    "predictions_amal = f_A.predict(cov_test)\n",
    "evaluate(predictions_amal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison to the $f_Y$ model may warn of the reinforcement of biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train on observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_observed = (tar_train['D'] == 1) if selective_labels else tar_train['D'].isin([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_Y = BinaryMLP(**params)\n",
    "f_Y = f_Y.fit(cov_train[index_observed], tar_train['Y1'][index_observed], nur_train[index_observed])\n",
    "predictions = f_Y.predict(cov_test)\n",
    "evaluate(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. Hybrid alternative\n",
    "\n",
    "- Leverage human model in the amalgamation set\n",
    "- Leverage outcome model on non amalgamation set\n",
    "\n",
    "Models need to be retrain on their respective subsets and calibrated to ensure to mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions_d.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute which test points are part of A for test set\n",
    "predictions_test, influence_test = influence_estimate(BinaryMLP, cov_train, tar_train['D'], nur_train, cov_test, params = params, l1_penalties = [0.001, 0.01, 0.1, 1])\n",
    "center_metric, opposing_metric = compute_agreeability(influence_test, predictions_test)\n",
    "flat_influence_test = (np.abs(influence_test) > pi_3).sum(0) == 0\n",
    "high_conf_test = (predictions_test > (1 - delta)) | (predictions_test < delta)\n",
    "high_agr_test = (((center_metric > pi_1) & (opposing_metric > pi_2)) | flat_influence_test) & high_conf_test\n",
    "high_agr_correct_test = ((predictions_test - tar_test['D']).abs() < delta) & high_agr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain a model on non almagamation only and calibrate: Rely on observed\n",
    "f_hyb = BinaryMLP(**params)\n",
    "f_hyb = f_hyb.fit(cov_train[index_observed], tar_train['Y1'][index_observed], nur_train[index_observed], platt_calibration = True)\n",
    "predictions[~high_agr_correct_test] = f_hyb.predict(cov_test.loc[~high_agr_correct_test])\n",
    "evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

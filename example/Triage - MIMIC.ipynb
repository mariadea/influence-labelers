{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC - Triage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the analysis on the MIMIC emergency data by leveraging experts' agreement\n",
    "1. Explore a model build on data ignoring experts \n",
    "2. Compute agreement between experts using influence function\n",
    "3. Retrain the model on the set of labels for which experts strongly agree\n",
    "\n",
    "The current analysis uses multi layer perceptrons in a single train / test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reopen the data created with the notebook in `data/`\n",
    "\n",
    "To use with your data, you will need to change the following line to open a file with:\n",
    "- `X` covariates\n",
    "- `H` associated (human) experts \n",
    "- `D` their decision for each case\n",
    "- `Y` observed outcome\n",
    "- `Yc` a concept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triage = pd.read_csv('../data/triage_clean.csv', index_col = [0, 1])\n",
    "covariates, target, nurses = triage.drop(columns = ['D', 'Y1', 'Y2', 'YC', 'acuity', 'nurse']), triage[['D', 'Y1', 'Y2', 'YC']], triage['nurse']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in a 80% train, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_train, cov_test, tar_train, tar_test, nur_train, nur_test = train_test_split(covariates, target, nurses, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's characteristics\n",
    "params = {'layers': []} # If = [] equivalent to a simple logistic regression\n",
    "\n",
    "# Amalgation parameters\n",
    "rho = 0.05 # Control which point to consider from a confience point of view\n",
    "pi_1 = 4.0 # Control criterion on centre mass metric\n",
    "pi_2 = 0.8 # Control criterion on opposing metric\n",
    "tau = 1.0  # Balance between observed and expert labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train on decision\n",
    "\n",
    "This model models the nurse decision based on covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train, tar_train['D'], nur_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D performance\n",
    "roc_auc_score(tar_test['D'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Agreement computation \n",
    "\n",
    "Measure of agreeability are estimated in a cross validation fashion on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fold evaluation of influences\n",
    "folds, predictions, influence = influence_cv(BinaryMLP, cov_train, tar_train['D'], nur_train, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics agreeability\n",
    "center_metric, opposing_metric = compute_agreeability(influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria on amalgamation\n",
    "high_conf = (predictions > (1 - rho)) | (predictions < rho)\n",
    "high_agr = (center_metric > pi_1) & (opposing_metric > pi_2) & high_conf\n",
    "high_agr_correct = ((predictions - tar_train['D']).abs() < rho) & high_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amalgamated labels\n",
    "tar_train['Ya'] = tar_train['Y1']\n",
    "tar_train['Ya'][high_agr_correct] = (1 - tau) * tar_train['Y1'][high_agr_correct] \\\n",
    "                                    + tau * tar_train['D'][high_agr_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_amalg = tar_train['D'] | high_agr_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train[index_amalg], tar_train[index_amalg]['Ya'], nur_train[index_amalg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D performance\n",
    "roc_auc_score(tar_test['D'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train on observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train, tar_train['Y1'], nur_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D performance\n",
    "roc_auc_score(tar_test['D'], model.predict(cov_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('Jupyter')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "\n",
    "from utils_synthetic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load child welfare synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the analysis on the childwelfare data by leveraging experts' agreement\n",
    "1. Explore a model build on data ignoring experts \n",
    "2. Compute agreement between experts using influence function\n",
    "3. Retrain the model on the set of labels for which experts strongly agree\n",
    "\n",
    "The current analysis uses multi layer perceptrons in a single train / test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reopen the data created with the notebook in `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../../../data/semi_synthetic/Data_semisynthetic_v1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'rb') as handle:\n",
    "    X,Y_1,Y_2,Y,D_0,refer_ids,screener_ids,coef_pred_y = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop instances if expert assessed a single case\n",
    "\n",
    "drop_experts = []\n",
    "for num in screener_ids:\n",
    "\n",
    "    if screener_ids.count(num) < 10:\n",
    "\n",
    "        drop_experts.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = []\n",
    "for index, elem in enumerate(screener_ids):\n",
    "    if elem in drop_experts:\n",
    "        drop_idx.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[53,\n",
       " 59,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 1112,\n",
       " 1150,\n",
       " 1151,\n",
       " 1154,\n",
       " 3288,\n",
       " 3289,\n",
       " 9749,\n",
       " 16779,\n",
       " 16780,\n",
       " 25172,\n",
       " 38533]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46544,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X,drop_idx,axis=0)\n",
    "Y_1 = np.delete(Y_1,drop_idx,axis=0)\n",
    "Y_2 = np.delete(Y_2,drop_idx,axis=0)\n",
    "Y = np.delete(Y,drop_idx,axis=0)\n",
    "D_0 = np.delete(D_0,drop_idx,axis=0)\n",
    "refer_ids = np.delete(refer_ids,drop_idx,axis=0)\n",
    "screener_ids = np.delete(screener_ids,drop_idx,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selective_labels = True\n",
    "#noise = True\n",
    "opb = True\n",
    "opb_blind = False\n",
    "\n",
    "unobservables = False\n",
    "unobs_k = 5 #number of unobsevables, k features with largest coefficient\n",
    "\n",
    "change_some_coef = False #resample some coefficients for each human?\n",
    "change_same = False\n",
    "n=44#how many coefficients to change if change_some_coef == True\n",
    "shared_bias = False\n",
    "bias_opposite = False #if shared_bias true, should the bias overestimate the importance of use it in the opposite direction?\n",
    "\n",
    "bias_assignment = False\n",
    "change_all_coef = False#resample all non-zero coefficients?\n",
    "\n",
    "random_if_not_good = False\n",
    "\n",
    "#If opb_out, modeled as a business rule?\n",
    "business_rule = False\n",
    "\n",
    "#selective labels? Do we only observe label when D=1?\n",
    "\n",
    "\n",
    "#HUMAN DECISIONS MODEL PARAMETERS\n",
    "\n",
    "rand = False #are decisions made by humans random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3371662316602846\n",
      "0.15438842991404697\n",
      "1.2789898467937826\n",
      "-0.5668497903127191\n",
      "-0.1829263795552658\n",
      "-0.062173478366350274\n",
      "0.16686433336210982\n",
      "-0.5196630298510732\n",
      "0.8557966681575077\n",
      "-0.41254153918521785\n",
      "-0.034568934494623435\n",
      "-0.2999388973192902\n",
      "-0.26663512234945325\n",
      "0.15126214282745998\n",
      "0.2668092773520606\n",
      "0.23022723616032145\n",
      "0.7164520061564308\n",
      "0.34504177535971065\n",
      "0.2520944370709525\n",
      "-0.03751832852234079\n",
      "0.16326508177332555\n",
      "0.9086757588320169\n",
      "1.062757900298296\n",
      "0.34004277245411335\n",
      "-0.4127702969163972\n",
      "0.4762979117261796\n",
      "0.3451015770506714\n",
      "-0.541994235684026\n",
      "-0.8851478283605279\n",
      "-0.7422020795708525\n",
      "0.042318364308891826\n",
      "1.0994399316965144\n",
      "-0.027574458210725825\n",
      "0.453296939477304\n",
      "0.453296939477304\n",
      "0.8813402682255846\n"
     ]
    }
   ],
   "source": [
    "if not opb:\n",
    "        Y = Y_1\n",
    "elif opb_blind and not business_rule:\n",
    "    Y = np.array([((Y_1[i]==1)&(D_0[i]==0)) for i in np.arange(len(Y_1))])\n",
    "    Y_2 = 1-D_0\n",
    "    logit = linear_model.LogisticRegression(penalty = 'l1', C=0.01, random_state=42, fit_intercept=False)\n",
    "    clf = logit.fit(X, Y)\n",
    "    Y_pred = clf.predict_proba(X)\n",
    "    fpr, tpr,thres = sklearn.metrics.roc_curve(Y, Y_pred[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    #print(roc_auc)\n",
    "    coef_pred_y = clf.coef_\n",
    "    #print(sum(coef_pred_y[0]!=0))\n",
    "    #plt.plot(fpr, tpr, color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "elif opb_blind and business_rule:\n",
    "    Y_2 = 1-D_0\n",
    "\n",
    "\n",
    "\n",
    "if unobservables: #delete one of the variables that receive a lot of weight\n",
    "    X_obs = np.delete(X,np.argsort(coef_pred_y[0])[-(unobs_k+2):-2],1)\n",
    "else:\n",
    "    X_obs = X\n",
    "\n",
    "if bias_assignment:\n",
    "    screener_ids = np.array(screener_ids)\n",
    "    screener_ids[X[:,-2] == max(X[:,-2])] = 'TNew'\n",
    "    screener_ids=list(screener_ids)\n",
    "\n",
    "screener_set = np.array([x for x in set(screener_ids) if str(x)!='nan'])\n",
    "\n",
    "D, alphas = decision_model(X, screener_ids, screener_set, coef_pred_y[0], change_coef = change_some_coef, change_same = change_same, change_all=change_all_coef, n=n,  shared_bias=shared_bias, rand= rand, bias_opposite=bias_opposite, bias_assignment= bias_assignment, random_if_not_good = random_if_not_good)\n",
    "\n",
    "if opb and opb_blind and business_rule:\n",
    "    D[D_0] = 0\n",
    "    Y[D_0] = 0\n",
    "\n",
    "#     with open('../../data/semi_synthetic/Y_human_'+setting+'.pkl', 'wb') as file:\n",
    "#         pkl.dump([X,Y_1,Y_2,Y,D_0,refer_ids,screener_ids,coef_pred_y,D],file)\n",
    "print(sum(D)/len(D))   \n",
    "print(sum(D==Y)/len(D)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_2 = Y_2*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "YC = [max(Y_1[i], Y_2[i]) for i in np.arange(len(Y_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame({'D': D, 'Y1': Y_1, 'Y2': Y_2, 'YC': YC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>D</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "      <th>YC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46523</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46524</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46525</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46526</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46527</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46528 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         D   Y1  Y2   YC\n",
       "0      1.0  1.0   1  1.0\n",
       "1      1.0  1.0   1  1.0\n",
       "2      1.0  0.0   1  1.0\n",
       "3      0.0  1.0   0  1.0\n",
       "4      0.0  0.0   0  0.0\n",
       "...    ...  ...  ..  ...\n",
       "46523  1.0  0.0   1  1.0\n",
       "46524  0.0  0.0   0  0.0\n",
       "46525  0.0  0.0   0  0.0\n",
       "46526  0.0  0.0   0  0.0\n",
       "46527  1.0  0.0   1  1.0\n",
       "\n",
       "[46528 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#covariates, target, nurses = triage.drop(columns = ['D', 'Y1', 'Y2', 'YC', 'acuity', 'nurse']), triage[['D', 'Y1', 'Y2', 'YC']], triage['nurse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_map = {}\n",
    "# screener_ids\n",
    "# for i in range(len(set(screener_ids))):\n",
    "#     ids_map[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert screener ids to integers\n",
    "#screener_ids = [int(i[2:]) for i in screener_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in a 80% train, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_train, cov_test, tar_train, tar_test, nur_train, nur_test = train_test_split(pd.DataFrame(X), target, pd.Series(screener_ids), test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's characteristics\n",
    "params = {'layers': []} # If = [] equivalent to a simple logistic regression\n",
    "\n",
    "# Amalgation parameters\n",
    "rho = 0.05 # Control which point to consider from a confience point of view\n",
    "pi_1 = 4.0 # Control criterion on centre mass metric\n",
    "pi_2 = 0.8 # Control criterion on opposing metric\n",
    "tau = 1.0  # Balance between observed and expert labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train on decision\n",
    "\n",
    "This model models the nurse decision based on covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.323: 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]\n"
     ]
    }
   ],
   "source": [
    "for l1_penalty in [0.001, 0.01]:\n",
    "    try:\n",
    "        model = BinaryMLP(**params)\n",
    "        model = model.fit(cov_train, tar_train['D'], nur_train, l1_penalty = l1_penalty)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e, l1_penalty)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9197947450603479"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8606437059723931"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['Y2'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.949400611791916"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(tar_test['YC'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9571604173914081"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(tar_test['D'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Agreement computation \n",
    "\n",
    "Measure of agreeability are estimated in a cross validation fashion on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'T095467': 4119,\n",
       "         'T096208': 4973,\n",
       "         'T060875': 2483,\n",
       "         'T084791': 3499,\n",
       "         'T091442': 2400,\n",
       "         'T094595': 2384,\n",
       "         'T044996': 1642,\n",
       "         'T066265': 4137,\n",
       "         'T071543': 142,\n",
       "         'T096966': 2834,\n",
       "         'T098306': 1245,\n",
       "         'T055473': 4877,\n",
       "         'T079344': 4547,\n",
       "         'T069459': 642,\n",
       "         'T092753': 1123,\n",
       "         'T098337': 701,\n",
       "         'T078534': 27,\n",
       "         'T087566': 382,\n",
       "         'T102928': 444,\n",
       "         'T102948': 59,\n",
       "         'T098938': 33,\n",
       "         'T098007': 161,\n",
       "         'T101142': 2135,\n",
       "         'T104299': 196,\n",
       "         'T083062': 405,\n",
       "         'T101854': 181,\n",
       "         'T105008': 43,\n",
       "         'T104369': 77,\n",
       "         'T105222': 42,\n",
       "         'T105208': 30,\n",
       "         'T099724': 44,\n",
       "         'T099665': 495,\n",
       "         'T105837': 26})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(screener_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('<U7')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screener_ids.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_cv(model, x, y, h, params = {}, fit_params = {}, n_split = 3):\n",
    "    \"\"\"\n",
    "    Compute a stratified cross validation to estimate the influence of each points\n",
    "\n",
    "    Args:\n",
    "        model (Object): Create a model (need to have predict and influence functions)\n",
    "        x (np.array pd.DataFrame): Covariates\n",
    "        y (np.array pd.DataFrame): Associated outcome\n",
    "        h (np.array pd.DataFrame): Associated expert\n",
    "        params (Dict): Dictionary to initialize the model with\n",
    "        fit_params (Dict): Dictionary for training\n",
    "        split (int): Number of fold used for the stratified computation of influence\n",
    "\n",
    "    Returns:\n",
    "        folds, predictions, influence: Arrays of each point fold, predictions by the model and influence (dim len(x) * num experts)\n",
    "    \"\"\"\n",
    "    x, y, h = (x.values, y.values, h.values) if isinstance(x, pd.DataFrame) else (x, y, h)\n",
    "\n",
    "    # Shuffle data - Need separation from fold to ensure group\n",
    "    sort = np.arange(len(h))\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(sort)\n",
    "    x, y, h = x[sort], y[sort], h[sort]\n",
    "    print(h)\n",
    "    # Create groups of observations to ensure one expert in each fold\n",
    "    #h_unique = np.unique(h)\n",
    "    g, unique_h = np.zeros_like(h), np.unique(h)\n",
    "    for expert in unique_h:\n",
    "        selection = h == expert\n",
    "        g[selection] = np.arange(np.sum(selection))\n",
    "\n",
    "    splitter = StratifiedGroupKFold(n_split, shuffle = False)\n",
    "    folds, predictions, influence = np.zeros(len(x)), np.zeros(len(x)), np.zeros((len(unique_h), x.shape[0]))\n",
    "    for i, (train_index, test_index) in enumerate(splitter.split(x, y, g)):\n",
    "        folds[test_index] = i\n",
    "        train_index, val_index = train_test_split(np.array(train_index), test_size = 0.15, shuffle = False)\n",
    "\n",
    "        # Train model on the subset\n",
    "        model_cv = model(**params)\n",
    "        model_cv.fit(x[train_index], y[train_index], h[train_index], **fit_params, val = (x[val_index], y[val_index]))\n",
    "\n",
    "        # Calibrate NN on validation set - Platt\n",
    "        pred_val = model_cv.predict(x[val_index])\n",
    "        pred_test = model_cv.predict(x[test_index])\n",
    "        calibrated = LogisticRegression().fit(pred_val, y[val_index])\n",
    "        predictions[test_index] = calibrated.predict_proba(pred_test)[:, 1]\n",
    "\n",
    "        # Compute influence\n",
    "        influence[:, test_index] = model_cv.influence(x[test_index])\n",
    "\n",
    "    return folds, predictions, influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T101142' 'T044996' 'T055473' ... 'T095467' 'T044996' 'T096966']\n",
      "T044996\n",
      "1324\n",
      "T055473\n",
      "3858\n",
      "T060875\n",
      "1979\n",
      "T066265\n",
      "3347\n",
      "T069459\n",
      "527\n",
      "T071543\n",
      "119\n",
      "T078534\n",
      "24\n",
      "T079344\n",
      "3637\n",
      "T083062\n",
      "313\n",
      "T084791\n",
      "2805\n",
      "T087566\n",
      "307\n",
      "T091442\n",
      "1916\n",
      "T092753\n",
      "881\n",
      "T094595\n",
      "1921\n",
      "T095467\n",
      "3325\n",
      "T096208\n",
      "3970\n",
      "T096966\n",
      "2273\n",
      "T098007\n",
      "129\n",
      "T098306\n",
      "996\n",
      "T098337\n",
      "558\n",
      "T098938\n",
      "26\n",
      "T099665\n",
      "401\n",
      "T099724\n",
      "33\n",
      "T101142\n",
      "1675\n",
      "T101854\n",
      "142\n",
      "T102928\n",
      "351\n",
      "T102948\n",
      "45\n",
      "T104299\n",
      "168\n",
      "T104369\n",
      "61\n",
      "T105008\n",
      "34\n",
      "T105208\n",
      "25\n",
      "T105222\n",
      "31\n",
      "T105837\n",
      "21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.363: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "Loss: 0.362: 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "Loss: 0.362: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fold evaluation of influences\n",
    "folds, predictions, influence = influence_cv(BinaryMLP, cov_train, tar_train['D'], nur_train, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics agreeability\n",
    "center_metric, opposing_metric = compute_agreeability(influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria on amalgamation\n",
    "high_conf = (predictions > (1 - rho)) | (predictions < rho)\n",
    "high_agr = (center_metric > pi_1) & (opposing_metric > pi_2) & high_conf\n",
    "high_agr_correct = ((predictions - tar_train['D']).abs() < rho) & high_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13443/148226879.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tar_train['Ya'] = tar_train['Y1'].copy()\n",
      "/home/vincent/miniconda3/envs/Jupyter/lib/python3.9/site-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return self._update_inplace(result)\n"
     ]
    }
   ],
   "source": [
    "# Create amalgamated labels\n",
    "tar_train['Ya'] = tar_train['Y1'].copy()\n",
    "tar_train['Ya'][high_agr_correct] = (1 - tau) * tar_train['Y1'][high_agr_correct] \\\n",
    "                                    + tau * tar_train['D'][high_agr_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_amalg = tar_train['D'] | high_agr_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.623:   2%|▏         | 23/1000 [00:08<06:13,  2.62it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train[index_amalg], tar_train[index_amalg]['Ya'], nur_train[index_amalg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6490108254809583"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5658628634431628"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train on observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.687:  13%|█▎        | 128/1000 [01:55<13:04,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train, tar_train['Y1'], nur_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6532088012868359"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5464182542438537"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

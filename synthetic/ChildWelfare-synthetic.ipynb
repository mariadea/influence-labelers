{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from model import *\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils_synthetic import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.2'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load child welfare synthetic data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook runs the analysis on the childwelfare data by leveraging experts' agreement\n",
    "1. Explore a model build on data ignoring experts \n",
    "2. Compute agreement between experts using influence function\n",
    "3. Retrain the model on the set of labels for which experts strongly agree\n",
    "\n",
    "The current analysis uses multi layer perceptrons in a single train / test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reopen the data created with the notebook in `data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../../../data/semi_synthetic/Data_semisynthetic_v1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_file, 'rb') as handle:\n",
    "    X,Y_1,Y_2,Y,D_0,refer_ids,screener_ids,coef_pred_y = pkl.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X,np.ones((X.shape[0],1)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop instances if expert assessed a single case\n",
    "\n",
    "drop_experts = []\n",
    "for num in screener_ids:\n",
    "\n",
    "    if screener_ids.count(num) < 10:\n",
    "\n",
    "        drop_experts.append(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_idx = []\n",
    "for index, elem in enumerate(screener_ids):\n",
    "    if elem in drop_experts:\n",
    "        drop_idx.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.delete(X,drop_idx,axis=0)\n",
    "Y_1 = np.delete(Y_1,drop_idx,axis=0)\n",
    "Y_2 = np.delete(Y_2,drop_idx,axis=0)\n",
    "Y = np.delete(Y,drop_idx,axis=0)\n",
    "D_0 = np.delete(D_0,drop_idx,axis=0)\n",
    "refer_ids = np.delete(refer_ids,drop_idx,axis=0)\n",
    "screener_ids = np.delete(screener_ids,drop_idx,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "selective_labels = True\n",
    "#noise = True\n",
    "opb = True\n",
    "opb_blind = False\n",
    "\n",
    "unobservables = False\n",
    "unobs_k = 5 #number of unobsevables, k features with largest coefficient\n",
    "\n",
    "change_some_coef = False #resample some coefficients for each human?\n",
    "change_same = False\n",
    "n=44#how many coefficients to change if change_some_coef == True\n",
    "shared_bias = False\n",
    "bias_opposite = False #if shared_bias true, should the bias overestimate the importance of use it in the opposite direction?\n",
    "\n",
    "bias_assignment = False\n",
    "change_all_coef = False#resample all non-zero coefficients?\n",
    "\n",
    "random_if_not_good = False\n",
    "\n",
    "#If opb_out, modeled as a business rule?\n",
    "business_rule = False\n",
    "\n",
    "#selective labels? Do we only observe label when D=1?\n",
    "\n",
    "\n",
    "#HUMAN DECISIONS MODEL PARAMETERS\n",
    "\n",
    "rand = False #are decisions made by humans random?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (4137,218) and (217,) not aligned: 218 (dim 1) != 217 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-165-1575a9b51919>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mscreener_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreener_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecision_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreener_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreener_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_pred_y\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_coef\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_some_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchange_same\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchange_all_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mshared_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshared_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_opposite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias_opposite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_assignment\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbias_assignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_if_not_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_if_not_good\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mopb\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mopb_blind\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbusiness_rule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FairML/Influence/repos/influence-labelers/synthetic/utils_synthetic.py\u001b[0m in \u001b[0;36mdecision_model\u001b[0;34m(X, screener_ids, screeners_set, coef_pred_y, change_coef, change_same, change_all, n, shared_bias, rand, bias_opposite, bias_assignment, random_if_not_good)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdecision_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreener_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreeners_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_pred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_coef\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_same\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_all\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mshared_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_opposite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_assignment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_if_not_good\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreener_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreeners_set\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mcoef_pred_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_coef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_same\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchange_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_opposite\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mbias_assignment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_if_not_good\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/FairML/Influence/repos/influence-labelers/synthetic/utils_synthetic.py\u001b[0m in \u001b[0;36mlabel_h\u001b[0;34m(X, screener_ids, screeners_set, coef_pred_y, change_coef, change_same, change_all, n, shared_bias, rand, bias_opposite, bias_assignment, random_if_not_good)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#print('after',coef)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m#time.sleep(10)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m#print(np.mean(pr),np.std(pr))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (4137,218) and (217,) not aligned: 218 (dim 1) != 217 (dim 0)"
     ]
    }
   ],
   "source": [
    "if not opb:\n",
    "        Y = Y_1\n",
    "elif opb_blind and not business_rule:\n",
    "    Y = np.array([((Y_1[i]==1)&(D_0[i]==0)) for i in np.arange(len(Y_1))])\n",
    "    Y_2 = 1-D_0\n",
    "    logit = linear_model.LogisticRegression(penalty = 'l1', C=0.01, random_state=42, fit_intercept=False)\n",
    "    clf = logit.fit(X, Y)\n",
    "    Y_pred = clf.predict_proba(X)\n",
    "    fpr, tpr,thres = sklearn.metrics.roc_curve(Y, Y_pred[:,1])\n",
    "    roc_auc = sklearn.metrics.auc(fpr, tpr)\n",
    "    #print(roc_auc)\n",
    "    coef_pred_y = clf.coef_\n",
    "    #print(sum(coef_pred_y[0]!=0))\n",
    "    #plt.plot(fpr, tpr, color='darkorange',label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "elif opb_blind and business_rule:\n",
    "    Y_2 = 1-D_0\n",
    "\n",
    "\n",
    "\n",
    "if unobservables: #delete one of the variables that receive a lot of weight\n",
    "    X_obs = np.delete(X,np.argsort(coef_pred_y[0])[-(unobs_k+2):-2],1)\n",
    "else:\n",
    "    X_obs = X\n",
    "\n",
    "if bias_assignment:\n",
    "    screener_ids = np.array(screener_ids)\n",
    "    screener_ids[X[:,-2] == max(X[:,-2])] = 'TNew'\n",
    "    screener_ids=list(screener_ids)\n",
    "\n",
    "screener_set = np.array([x for x in set(screener_ids) if str(x)!='nan'])\n",
    "\n",
    "D, alphas = decision_model(X, screener_ids, screener_set, coef_pred_y[0], change_coef = change_some_coef, change_same = change_same, change_all=change_all_coef, n=n,  shared_bias=shared_bias, rand= rand, bias_opposite=bias_opposite, bias_assignment= bias_assignment, random_if_not_good = random_if_not_good)\n",
    "\n",
    "if opb and opb_blind and business_rule:\n",
    "    D[D_0] = 0\n",
    "    Y[D_0] = 0\n",
    "\n",
    "#     with open('../../data/semi_synthetic/Y_human_'+setting+'.pkl', 'wb') as file:\n",
    "#         pkl.dump([X,Y_1,Y_2,Y,D_0,refer_ids,screener_ids,coef_pred_y,D],file)\n",
    "print(sum(D)/len(D))   \n",
    "print(sum(D==Y)/len(D)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_2 = Y_2*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YC = [max(Y_1[i], Y_2[i]) for i in np.arange(len(Y_1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame({'D': D, 'Y1': Y_1, 'Y2': Y_2, 'YC': YC})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"D!=Y1: \",sum(target['D']!=target['Y1']))\n",
    "print(\"Y2!=Y1: \",sum(target['Y2']!=target['Y1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#covariates, target, nurses = triage.drop(columns = ['D', 'Y1', 'Y2', 'YC', 'acuity', 'nurse']), triage[['D', 'Y1', 'Y2', 'YC']], triage['nurse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids_map = {}\n",
    "# screener_ids\n",
    "# for i in range(len(set(screener_ids))):\n",
    "#     ids_map[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert screener ids to integers\n",
    "#screener_ids = [int(i[2:]) for i in screener_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data in a 80% train, 20% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_train, cov_test, tar_train, tar_test, nur_train, nur_test = train_test_split(pd.DataFrame(X), target, pd.Series(screener_ids), test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model's characteristics\n",
    "params = {'layers': []} # If = [] equivalent to a simple logistic regression\n",
    "\n",
    "# Amalgation parameters\n",
    "rho = 0.05 # Control which point to consider from a confience point of view\n",
    "pi_1 = 4.0 # Control criterion on centre mass metric\n",
    "pi_2 = 0.8 # Control criterion on opposing metric\n",
    "tau = 1.0  # Balance between observed and expert labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Train on decision\n",
    "\n",
    "This model models the nurse decision based on covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1_penalty in [1.0, 0.1, 0.001, 0.01]:\n",
    "    try:\n",
    "        model = BinaryMLP(**params)\n",
    "        model = model.fit(cov_train, tar_train['D'], nur_train, l1_penalty = l1_penalty)\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(e, l1_penalty)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['Y2'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['YC'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['D'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Agreement computation \n",
    "\n",
    "Measure of agreeability are estimated in a cross validation fashion on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fold evaluation of influences\n",
    "folds, predictions, influence = influence_cv(BinaryMLP, cov_train, tar_train['D'], nur_train, params = params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics agreeability\n",
    "center_metric, opposing_metric = compute_agreeability(influence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(center_metric, opposing_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply criteria on amalgamation\n",
    "high_conf = (predictions > (1 - rho)) | (predictions < rho)\n",
    "high_agr = (center_metric > pi_1) & (opposing_metric > pi_2) & high_conf\n",
    "high_agr_correct = ((predictions - tar_train['D']).abs() < rho) & high_agr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('high_conf:', sum(high_conf))\n",
    "print('high_agr:', sum(high_agr))\n",
    "print('high_agr_correct:', sum(high_agr_correct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "prob_true, prob_pred = calibration_curve(tar_train['D'], predictions, n_bins=7)\n",
    "plt.plot(prob_true,prob_pred, marker='o', linewidth=1, label='logreg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create amalgamated labels\n",
    "tar_train['Ya'] = tar_train['Y1'].copy()\n",
    "tar_train['Ya'][high_agr_correct] = (1 - tau) * tar_train['Y1'][high_agr_correct] \\\n",
    "                                    + tau * tar_train['D'][high_agr_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tar_train['D']!=tar_train['Y1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_train['Y1'][high_agr_correct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(tar_train['Ya']!=tar_train['Y1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index for selective labels\n",
    "index_amalg = [i==1.0 for i in tar_train['D']] | high_agr_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Updated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model with selective labels\n",
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train[index_amalg], tar_train[index_amalg]['Ya'], nur_train[index_amalg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model without selective labels\n",
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train, tar_train['Ya'], nur_train[index_amalg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['Y2'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['D'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Train on observed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryMLP(**params)\n",
    "model = model.fit(cov_train, tar_train['Y1'], nur_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive performance\n",
    "roc_auc_score(tar_test['Y1'], model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yc performance\n",
    "roc_auc_score(tar_test['YC'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['Y2'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(tar_test['D'],model.predict(cov_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a54f3b3a447186e9a4a83057d2abe8df010acd7b8f131225203d307ef84eba48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
